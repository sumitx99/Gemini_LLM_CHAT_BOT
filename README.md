## âœ¨ Gemini LLM CHAT BOT

This is a Streamlit-based application that uses Google's Gemini API to provide a conversational Q&A interface. Users can input questions, and the app returns responses generated by the `gemini-pro` model.

![image](https://github.com/user-attachments/assets/f70dc0a8-ee02-45d2-93d4-bf0a2b7447d7)

## ğŸŒŸ Features

- ğŸ–¥ï¸ **Interactive Q&A Interface**: Powered by Streamlit.
- ğŸ¤– **Google's Gemini API Integration**: Utilizing advanced language models.
- ğŸ“œ **Chat History**: Maintains conversation history during the session.
- ğŸ”„ **Real-time Streaming**: Immediate response streaming.

## ğŸ“‹ Prerequisites

- ğŸ Python 3.7 or higher
- ğŸ”‘ Google API Key

## ğŸ“¦ Installation

1. Navigate to the project directory:
    ```bash
    cd your-repo-name
    ```
2. Install the dependencies:
    ```bash
    pip install -r requirements.txt
    ```
3. Create a `.env` file in the root directory and add your Google API key:
    ```plaintext
    GOOGLE_API_KEY=your_actual_google_api_key_here
    ```
    
## ğŸš€ Usage

1. Run the Streamlit app:
    ```bash
    streamlit run your_script_name.py
    ```
2. Open the URL provided by Streamlit to interact with the app.

## ğŸ“ Project Structure

- `your_script_name.py`: Main application file.
- `requirements.txt`: List of dependencies.
- `.env`: Environment variables file (not included in the repository for security).
- `README.md`: Documentation file.

## ğŸ’¡ Example

After running the app, you'll see an input field to enter your question and a button to submit it. The app will display the response from the Gemini model and maintain the chat history in the session.


## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™Œ Acknowledgements

- [Streamlit](https://streamlit.io/) ğŸ’»
- [Google Generative AI](https://cloud.google.com/generative-ai) ğŸŒ
- [Python Dotenv](https://pypi.org/project/python-dotenv/) ğŸ› ï¸
